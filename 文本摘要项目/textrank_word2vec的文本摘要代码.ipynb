{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c001c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cchardet\n",
    "import re\n",
    "from textrank4zh import TextRank4Keyword, TextRank4Sentence\n",
    "import jieba\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b04fcc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class textSummary(object):\n",
    "    def __init__(self,N):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "    \n",
    "    def drop_brackets_content(self,sentence):\n",
    "        \"\"\"\n",
    "        清除括号中内容\n",
    "        \"\"\"\n",
    "        pattern  = \"（[\\s\\S]*?）\"\n",
    "        res = re.sub(pattern,\"\",sentence)\n",
    "        return res\n",
    "    \n",
    "    def clean_sentence(self,sentence):\n",
    "        \"\"\"\n",
    "        去掉空格和换行符\n",
    "        \"\"\"\n",
    "        clean_sentence = sentence.replace(\"\\r\\n\",\"\").replace(\"　　\",\"\")\n",
    "        return clean_sentence\n",
    "    \n",
    "    def cut_sents(self,content):\n",
    "        \"\"\"\n",
    "        对句子完成切割--分句\n",
    "        \"\"\"\n",
    "        sentences = re.split(r\"([。!！?？；;])\", content)[:-1]\n",
    "        sentences.append(\"\")\n",
    "        sentences = [\"\".join(i) for i in zip(sentences[0::2],sentences[1::2])]\n",
    "        return sentences\n",
    "    \n",
    "    def clean_and_drop_brackets_content(self,sentence):\n",
    "        \"\"\"\n",
    "        清除括号内容和空格\n",
    "        \"\"\"\n",
    "        return self.clean_sentence(self.drop_brackets_content(sentence))\n",
    "    \n",
    "    def segmentation_sentence(self,sentence):\n",
    "        \"\"\"\n",
    "        清理加分句\n",
    "        \"\"\"\n",
    "        return self.cut_sents(self.clean_sentence(self.drop_brackets_content(sentence)))\n",
    "    \n",
    "    \n",
    "    def save_key_word(self,sentence):\n",
    "        \"\"\"\n",
    "        通过textrank获取关键词\n",
    "        \"\"\"\n",
    "        tr4w = TextRank4Keyword()\n",
    "        tr4w.analyze(text=sentence, lower=True, window=2)\n",
    "        save_key_word_list = []\n",
    "        for item in tr4w.get_keywords(50, word_min_len=1):\n",
    "            save_key_word_list.append((item.word, item.weight))\n",
    "        return save_key_word_list\n",
    "    \n",
    "    \n",
    "    def cut_word_test(self,context_list):\n",
    "        \"\"\"\n",
    "        切词获取所有单词的列表，制作词向量的前序操作\n",
    "        \"\"\"\n",
    "        stopkey=[line.strip() for line in open('stopwords.txt',encoding='utf-8').readlines()]\n",
    "        total_cutword = []\n",
    "        for i in context_list:\n",
    "            words=jieba.cut(i)\n",
    "            words_filter=[word for word in words if word not in stopkey]\n",
    "            if len(words_filter) !=0:\n",
    "                total_cutword.append(words_filter)\n",
    "        return total_cutword\n",
    "    \n",
    "    def get_w2v_model(self,data,flag=1):\n",
    "        \"\"\"\n",
    "        拿到word2vec模型，flag=0,重新训练模型；flag=1,直接调用已经存在的模型\n",
    "        \"\"\"\n",
    "        if flag == 0:\n",
    "            print(\"计算词向量中，请稍后...\")\n",
    "            model = Word2Vec(data, size=256, window=5,iter=1000, min_count=1, workers=4)\n",
    "            model.save('model.bin')\n",
    "        else:\n",
    "            print(\"正在加载词向量\")\n",
    "            model = Word2Vec.load('model.bin')\n",
    "        return model\n",
    "    \n",
    "    def get_similar_word(self,key_word_list,model):\n",
    "        \"\"\"\n",
    "        通过余弦相似度，完成对每个关键词的相似词的搜寻\n",
    "        \"\"\"\n",
    "        print(\"正在进行关键词相似词的搜寻\")\n",
    "        new_key_word = []\n",
    "        new_word_list = []\n",
    "        for key,value in tqdm(key_word_list,total=len(key_word_list)):\n",
    "            new_key_word.append((key,value))\n",
    "            new_word_list.append(key)\n",
    "            if key in model.wv.index2word:\n",
    "                _index = model.wv.index2word.index(key)\n",
    "                for index,word in enumerate(model.wv.index2word):\n",
    "                    if index == _index:\n",
    "                        continue\n",
    "                    else:\n",
    "                        cosine_value = cosine_similarity([model.wv.vectors[index],model.wv.vectors[_index]])\n",
    "                        if cosine_value[0][1] > 0.8:\n",
    "#                             print(\"{}和{}是相似的，相似度是：{}\".format(word,key,cosine_value[0][1]))\n",
    "                            if word not in new_word_list:\n",
    "                                new_key_word.append((word,value))\n",
    "                                new_word_list.append(word)\n",
    "        return new_key_word\n",
    "    \n",
    "    def get_sentence_score_list(self,sentence,title,new_key_word):\n",
    "        \"\"\"\n",
    "        得到句子的重要程度分数，默认title的分数是0.5，其他的句子的分数是句子中关键词的分数之和，最后按照分数由高到低排序\n",
    "        \"\"\"\n",
    "        print(\"正在获取句子的重要程度分数\")\n",
    "        new_sentence = self.segmentation_sentence(sentence)\n",
    "        sentence_score_list = []\n",
    "        for index,_sentence in enumerate(new_sentence):\n",
    "            score = 0\n",
    "            for key,value in new_key_word:\n",
    "                if key in _sentence:\n",
    "                    score += value\n",
    "            sentence_score_list.append((_sentence,score))\n",
    "        sentence_score_list.append((title+\"。\",0.5))\n",
    "        sentence_score_list.sort(key=lambda x:-x[1])\n",
    "        return sentence_score_list\n",
    "    \n",
    "    def output_summary(self,sentence_score_list):\n",
    "        \"\"\"\n",
    "        按照句子的分数取出句子进行拼接，直到逼近字数N为止\n",
    "        \"\"\"\n",
    "        sentence = \"\"\n",
    "        for key,value in sentence_score_list:\n",
    "            if len(sentence) < self.N:\n",
    "                sentence += key\n",
    "            else:\n",
    "                break\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc060a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_artical_summary(article=\"\",title=\"\",_index= -1,flag = 1):\n",
    "    \"\"\"\n",
    "    第一种：_index为-1，需要输入article和title的值，进行自定义文章摘要提取；\n",
    "    第二种：_index不为-1，指定chinese_news的文章id进行摘要提取\n",
    "    flag 如果有Word2vec的model,选1，没有模型，或者想重新训练，选0；\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"chinese_news.csv\",encoding=\"gb18030\")\n",
    "    df = df.dropna(subset = ['content',\"title\"])\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    ts = textSummary(100)\n",
    "    \n",
    "    # 截断数据，小规模测试\n",
    "    df = df[:201]\n",
    "    df.insert(loc=2, column='key_word', value=0)\n",
    "    if _index == -1:\n",
    "        if artical != \"\" and title != \"\":\n",
    "            print(\"当前填入自定义文章，进行摘要提取\")\n",
    "            _index = df.shape[0]\n",
    "            df.loc[_index] = [0,0,0,0,article,0,title,0]\n",
    "        else:\n",
    "            print(\"当前参数有误：第一种：_index为-1，需要输入article和title的值，进行自定义文章摘要提取；第二种：_index不为-1，指定chinese_news的文章id进行摘要提取\")\n",
    "    else:\n",
    "        print(\"当前_index的值不为-1，进行chinese_news指定文章的摘要提取\")\n",
    "\n",
    "    # 看不见执行进度，不用了\n",
    "    # new_df[\"key_word\"] = new_df[\"content\"].apply(save_key_word) \n",
    "\n",
    "    print(\"当前正在获取关键词，请稍等...\")\n",
    "    for index,content in tqdm(enumerate(df[\"content\"]),total=len(list(df[\"content\"]))):\n",
    "        df[\"key_word\"][index] = ts.save_key_word(content) \n",
    "    \n",
    "    total_cutword = ts.cut_word_test([ts.clean_and_drop_brackets_content(i) for i in list(df[\"content\"])])\n",
    "    model = ts.get_w2v_model(total_cutword,flag=flag)\n",
    "    new_key_word = ts.get_similar_word(df[\"key_word\"][_index],model)\n",
    "    return ts.output_summary(ts.get_sentence_score_list(df[\"content\"][_index],df[\"title\"][_index],new_key_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c7d960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前填入自定义文章，进行摘要提取\n",
      "当前正在获取关键词，请稍等...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18aae0d745540088cace52055ce08a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载词向量\n",
      "正在进行关键词相似词的搜寻\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33708302fe4547dfa2b87c0361865778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取句子的重要程度分数\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'十五的月亮十五圆 今年中秋哪里可见皓月当空？。从赏月地图来看，今年中秋节当天，西北地区和东南沿海赏月天气条件较好，新疆、青海、甘肃、宁夏、          陕西、内蒙古中西部及苏皖北部、浙江南部、福建、广东东部等地都将是皓月当空，能够清晰地看到天空中“白玉盘”般的圆月。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义文章和title,进行摘要提取\n",
    "get_input_artical_summary(\"从赏月地图来看，今年中秋节当天（9月10日），西北地区和东南沿海赏月天气条件较好，新疆、青海、甘肃、宁夏、\\\n",
    "                          陕西、内蒙古中西部及苏皖北部、浙江南部、福建、广东东部等地都将是皓月当空，能够清晰地看到天空中“白玉盘”般的圆月。\\\n",
    "                          东北大部、京津冀、山东、河南中北部、苏皖南部、湖北、重庆、广东西部、广西等地都将是多云或阴天，上演彩云追月，\\\n",
    "                          圆月时而冒头时而隐身，在云朵映衬下增添一份神秘感。而在山西大部、河北西部以及贵州、云南、四川盆地南部、西藏大部等地，\\\n",
    "                          云量较多，一些地方还会下雨，或许圆月难见，想一睹月亮真容，可以通过直播来云赏月。虽然是共赏同一轮明月，\\\n",
    "                          但赏月方式却是五花八门，既有充满诗情画意的登高望月、泛舟赏月等传统方式，随着科技的进步，如今还有合拍赏月、摩天轮赏月等新型赏月方式。\\\n",
    "                          在北方赏月，登高望月、合拍赏月等方式皆可解锁。在敦煌月牙泉，因当地纬度较高，还能享受“手可摘月亮”的极致体验，\\\n",
    "                          通过借位可拍出将月亮“托起”的照片，分分钟让你成为朋友圈最靓的仔。长春净月潭则可欣赏到“明月松间照”的美景，在松林的衬托下，\\\n",
    "                          月色更显静谧。南方水系众多，自古以来人们的赏月活动多与水有关。在杭州，西湖胜景平湖秋月、三潭印月是人们熟知的赏月胜地，泛舟湖上，\\\n",
    "                          能体会到“烟笼秋水月笼纱”的诗般意境。而黄山风景区拥有多个赏月佳地，光明顶最为开阔，登高望圆月一览无遗。\\\n",
    "                          如今合拍赏月和摩天轮赏月也越来越受人追捧。上海外滩及广州小蛮腰都是合拍赏月的胜地。南昌赣江沿岸的“南昌之星”摩天轮，\\\n",
    "                          也可让月亮如在眼前，唾手可得。\",\"十五的月亮十五圆 今年中秋哪里可见皓月当空？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9b579ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前_index的值不为-1，进行chinese_news指定文章的摘要提取\n",
      "当前正在获取关键词，请稍等...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd28532c54c44d38b6d7e6bdff17dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载词向量\n",
      "正在进行关键词相似词的搜寻\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ba6349ed8f4d539ae434727ada9d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在获取句子的重要程度分数\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'中超联赛第13轮比赛已经全部结束，这轮比赛中最让人觉得结果有些出乎意料的，莫过于卡佩罗执教江苏苏宁的主场首秀却以失败告终，在其他球队换帅如换刀的背景下，苏宁却持续陷入低迷，13轮过后只积8分，排名倒数第2，近3年1铁律预示苏宁想保级除非创造奇迹。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入0~200之间的标号，对chinese_news指定的文章进行摘要提取\n",
    "get_input_artical_summary(_index=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc38b063",
   "metadata": {},
   "source": [
    "### DONE\n",
    "- [x] 使用textrank获取关键词\n",
    "- [x] 使用word2vec词向量的训练\n",
    "- [x] 相似词语的计算\n",
    "- [x] 文本摘要的简易版本\n",
    "\n",
    "### TODO\n",
    "- [ ] 语义通顺，暂时没有方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c18fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6183d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0566718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddb68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
